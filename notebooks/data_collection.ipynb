{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTEXT\n",
    "\n",
    "I want to prove \n",
    "- if the idom \"drive for show putt for dough\" is true in respect to scores\n",
    "- the strongest factor affecting performance\n",
    "- predict the winning tournment scores\n",
    "- relations to golf winnings\n",
    "\n",
    "start with scraping data to build csv file (beutiful soup)\n",
    "https://www.pgatour.com/stats/stat/jcr:content/mainParsys/details.101.y2021.eon.t013.scontent.html\n",
    "\n",
    "- in the network look for .details calls with an html file\n",
    "\n",
    "  - score (round score)\n",
    "  - player average score\n",
    "  - greens in regulation\n",
    "  - fairways in regulation\n",
    "  - putts per round\n",
    "  - up and down conversions\n",
    "  - course design (stanley tompson)\n",
    "  - player home course design\n",
    "  - weather conditions\n",
    "  - is a major event\n",
    "  - player position in the golf rankings (may lead to more or less pressure)\n",
    "  - tournment leading score, compare to round score to see if there is a diference\n",
    "\n",
    "- I need to seperate categorical and numerical data and visual our data (cleaning data)\n",
    "- Collect significant values to run through ML or linear regression models\n",
    "- use a voting system to compare the models and give them weighs\n",
    "\n",
    "- present evidence in a visual format\n",
    "- explain findings\n",
    "\n",
    "\n",
    "NOTES\n",
    "- try to be to vague and deal with too many averages (years is too big, pick a specific tournment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA COLLECTION\n",
    "\n",
    "Let's begin by collecting data from \n",
    "\n",
    "\n",
    "\n",
    "Found the raw api collection of data in network\n",
    "Checked the /robots.txt and saw that it was no allowed to scrap from there\n",
    "\n",
    "Allowed to scrap from the stats directly\n",
    "\n",
    "https://www.owgr.com/ -> no robot.txt disallowance\n",
    "\n",
    "\n",
    "Plan for collecting data\n",
    "\n",
    "- Want to predict total earning\n",
    "- 1) get the season winning table\n",
    "- 2) determine the tournment payouts (exclude majors?)\n",
    "- 3) relationship to scoring average\n",
    "  - 4) stokes gained on off the tee, on the fairway, around the green, on the green\n",
    "  *Off-the-tee + approach-the-green + around-the-green + putting = strokes gained: total\n",
    "- Are stroked gained more important on certain courses (links, stadium, parkland course)\n",
    "\n",
    "  \n",
    "\n",
    "- what I want, given a tournment (golf course type + winnings), weather (effect strokes gained), average stokes gained (all aspects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a helper function to build our csv files based on our stat code and title. It will be important to rate limit our requests to not overwhelm the servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_frame_builder(title: str, statCd: int) -> pd.DataFrame:\n",
    "    dfs = []\n",
    "    for year in range(2019, 2022):\n",
    "        #rate limit our requests\n",
    "        time.sleep(2)\n",
    "        \n",
    "        #build the url and create a get request for the html\n",
    "        url = f'https://www.pgatour.com/stats/stat.{statCd}.y{year}.html'\n",
    "        rs = requests.get(url)\n",
    "        \n",
    "        #use panadas to read <table> tags and generate a data frame (second table on the page is desired)\n",
    "        dfs = pd.read_html(rs.text)\n",
    "        currDf = dfs[1]\n",
    "    \n",
    "        #add a year column\n",
    "        currDf['YEAR'] = year\n",
    "        \n",
    "        \n",
    "        #set the index of the data to a year\n",
    "        dfs.append(currDf)\n",
    "    \n",
    "    completedDf = pd.concat([*dfs], ignore_index=True)\n",
    "    \n",
    "    #clean the NaN data\n",
    "    cleanedDf = completedDf.dropna(axis=1, how='all')\n",
    "    cleanedDf = cleanedDf.drop(cleanedDf.columns[0], axis = 1)\n",
    "\n",
    "    return cleanedDf.shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the following data frames from 2010 - 2020, please refer each table definitions belows.\n",
    "\n",
    "Offical Money: Total compensation\n",
    "Scoring Average:\n",
    "\n",
    "Driving Distance:\n",
    "Driving Accuracy: The percentage of time a tee shot comes to rest in the fairway (regardless of club).\n",
    "\n",
    "Greens in Regulation: The percent of time a player was able to hit the green in regulation (greens hit in regulation/holes played). Note: A green is considered hit in regulation if any portion of the ball is touching the putting surface after the GIR stroke has been taken. (The GIR stroke is determined by subtracting 2 from par (1st stroke on a par 3, 2nd on a par 4, 3rd on a par 5))\n",
    "\n",
    "\n",
    "Scambling: The percent of time a player misses the green in regulation, but still makes par or better.\n",
    "Sand Saves: The percent of time a player was able to get 'up and down' once in a greenside sand bunker (regardless of score). Note: 'Up and down' indicates it took the player 2 shots or less to put the ball in the hole from that point.\n",
    "\n",
    "Putts Per Round:\n",
    "\n",
    "Par Three Performance: Average Score on Par 3's played\n",
    "Par Four Performance: Average Score on Par 4's played\n",
    "Par Five Performance: Average Score on Par 5's played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsMap = {\n",
    "  \"offical_money\" : 109,\n",
    "  \"scoring_average\" : 120,\n",
    "  \"driving_distance\" : 101,\n",
    "  \"driving_accuracy\" : 102,\n",
    "  \"greens_in_regulation\":103,\n",
    "  \"scrambling\": 130,\n",
    "  \"sand_saves\": 111,\n",
    "  \"putts_per_round\" : 119,\n",
    "  \"par_three_scoring_average\" : 142,\n",
    "  \"par_four_scoring_average\" : 143,\n",
    "  \"par_five_scoring_average\" : 144\n",
    "}\n",
    "\n",
    "#loop through the map and create new csv\n",
    "for title, val in statsMap.items():\n",
    "    newDf = data_frame_builder(title, val)\n",
    "    newDf.to_csv(f\"../data/raw_data/{title}.csv\", index=False)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
